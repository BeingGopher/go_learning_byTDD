# BeiSen_Interview(AI)

## 数据库索引

> 在 MySQL 中，**索引（Index）**是一种用于提高数据库查询效率的数据结构。它类似于书籍的目录，通过预先排序和存储数据的一部分，使得数据库系统能够快速定位到所需的数据行，从而加快查询速度。
>
> ## 索引类型
>
> ### 1. B 树索引（B-Tree Index）
> MySQL 默认的索引类型是 B+ 树（B-Tree 的一种变体），适用于大多数查询场景。B+ 树索引具有以下特点：
> • **有序存储**：索引列的值按升序排列，支持范围查询。
> • **平衡树结构**：保证所有叶子节点在同一层，查询性能稳定。
> • **支持多种查询**：等值查询、范围查询、排序和分组操作。
>
> ### 2. 哈希索引（Hash Index）
> 哈希索引基于哈希表实现，适用于等值查询（如 `WHERE column = value`），但不支持范围查询和排序。哈希索引的特点包括：
> • **快速查找**：通过哈希函数直接定位数据，查询速度极快。
> • **不支持有序操作**：无法用于 `ORDER BY` 或范围查询。
> • **存储引擎限制**：主要在 Memory 存储引擎中使用。
>
> ### 3. 全文索引（Full-Text Index）
> 全文索引用于全文搜索，适用于对文本内容进行复杂的搜索操作，如文章内容搜索。MySQL 从 5.6 版本开始支持 InnoDB 存储引擎的全文索引。其特点包括：
> • **支持自然语言搜索**：可以执行复杂的文本匹配查询。
> • **词元分词**：将文本拆分为词元，建立索引。
>
> ### 4. 空间索引（Spatial Index）
> 空间索引用于地理空间数据类型（如 `POINT`, `LINESTRING`），支持高效的空间查询。主要在 MyISAM 和 InnoDB 存储引擎中使用。
>
> ## 索引的工作原理
>
> 索引通过创建数据结构（如 B+ 树）来存储索引列的值及其对应的数据行指针。当执行查询时，数据库系统会先查找索引结构，快速定位到符合条件的数据行，从而避免全表扫描，提高查询效率。
>
> ## 索引的优点
>
> 1. **提高查询速度**：显著减少查询所需的时间，特别是在大数据量的表中效果明显。
> 2. **加速排序和分组操作**：索引可以帮助数据库快速完成 `ORDER BY` 和 `GROUP BY` 操作。
> 3. **优化连接操作**：在多表连接查询中，索引可以加快连接条件的匹配速度。
>
> ## 索引的缺点
>
> 1. **占用额外的存储空间**：索引需要占用额外的磁盘空间，尤其是在创建多个索引时。
> 2. **降低数据写入速度**：每次插入、更新或删除数据时，索引也需要相应地维护，可能影响写入性能。
> 3. **增加维护成本**：复杂的索引结构需要更多的系统资源进行维护，可能增加数据库的复杂性和管理难度。
>
> ## 使用索引的最佳实践
>
> 1. **选择合适的列创建索引**：
>    • 高选择性的列（即不同值较多的列）更适合创建索引。
>    • 经常用于 `WHERE` 子句、连接条件和排序的列应优先考虑索引。
>
> 2. **避免过度索引**：
>    • 每个额外的索引都会增加存储和维护成本，应根据实际查询需求创建必要的索引。
>    • 定期审查和优化索引，删除不再使用或冗余的索引。
>
> 3. **使用复合索引**：
>    • 对于多列查询条件，可以创建复合索引（多列组成的索引），提高查询效率。
>    • 注意复合索引的列顺序，应根据查询条件的使用频率和选择性进行优化。
>
> 4. **覆盖索引**：
>    • 确保查询能够通过索引直接获取所需的数据，避免回表操作，提高查询性能。
>
> 5. **监控和优化查询性能**：
>    • 使用 `EXPLAIN` 语句分析查询执行计划，了解索引的使用情况。
>    • 根据查询性能瓶颈调整索引策略。
>
> ## 常见索引相关操作
>
> ### 创建索引
>
> ```sql
> -- 创建单列索引
> CREATE INDEX idx_column_name ON table_name(column_name);
> 
> -- 创建复合索引
> CREATE INDEX idx_column1_column2 ON table_name(column1, column2);
> 
> -- 创建唯一索引
> CREATE UNIQUE INDEX idx_unique_column ON table_name(column_name);
> 
> -- 创建全文索引
> CREATE FULLTEXT INDEX idx_fulltext_column ON table_name(column_name);
> ```
>
> ### 删除索引
>
> ```sql
> -- 删除单列索引
> DROP INDEX idx_column_name ON table_name;
> 
> -- 删除复合索引
> DROP INDEX idx_column1_column2 ON table_name;
> ```
>
> ### 查看索引信息
>
> ```sql
> SHOW INDEX FROM table_name;
> ```
>

### MySQL 中的聚集索引

**聚集索引**是一种索引类型，其中索引的叶子节点不仅包含索引列的值，还包含实际的数据行。换句话说，数据行按照聚集索引的顺序在磁盘上物理存储。因此，在一个表中，**只能有一个聚集索引**，因为数据行只能按照一种顺序存储。

在 MySQL 的 **InnoDB** 存储引擎中，聚集索引的实现方式如下：

1. **主键索引（PRIMARY KEY）**：
   - 如果表定义了主键，InnoDB 会使用主键作为聚集索引。
   - 数据行按照主键的顺序存储。
2. **无主键时的唯一索引**：
   - 如果表没有定义主键，但有一个或多个唯一索引，InnoDB 会选择第一个唯一索引作为聚集索引。
3. **自动生成的隐藏列**：
   - 如果表既没有主键，也没有唯一索引，InnoDB 会自动生成一个隐藏的 **ROWID** 列作为聚集索引。

### 聚集索引的特点

- **物理顺序**：数据行按照聚集索引的顺序存储，因此范围查询（如 `BETWEEN`、`ORDER BY`）效率较高。
- **唯一性**：聚集索引保证了索引列的唯一性（前提是主键或唯一索引）。
- **覆盖索引**：由于数据行存储在索引叶子节点中，某些查询可以仅通过索引完成，避免回表操作，提高查询性能。

|     特性     | 聚集索引（Clustered Index） |      非聚集索引（Non-Clustered Index）       |
| :----------: | :-------------------------: | :------------------------------------------: |
| 数据存储方式 | 索引叶子节点包含实际数据行  |       索引叶子节点包含指向数据行的指针       |
| 每个表的数量 |         只能有一个          |                  可以有多个                  |
|   查询性能   |   对范围查询和排序更高效    | 需要通过索引查找后再访问数据行，可能涉及回表 |
|   适用场景   |     主键查询、范围查询      |            辅助查询条件、多列索引            |

## 内存泄漏和垃圾回收

在Go语言（Golang）中，内存泄漏和垃圾回收是两个重要的内存管理概念。下面我将分别介绍这两个概念。

### 内存泄漏

**内存泄漏**是指程序在申请内存后，由于疏忽或错误未能释放已不再使用的内存，导致这部分内存无法被再次使用，从而造成系统内存的浪费。随着程序运行时间的增长，未被释放的内存越来越多，可能导致程序占用的内存越来越大，最终耗尽系统资源。

在Go语言中，虽然有自动垃圾回收机制，但仍然可能发生内存泄漏，常见原因包括：

1. **全局变量**：全局变量生命周期长，如果持有大量数据且不及时清理，可能导致内存泄漏。
2. **闭包**：闭包可能会捕获外部变量，如果闭包长时间存在，可能导致这些变量无法被回收。
3. **goroutine泄漏**：如果goroutine在执行过程中被阻塞，且没有相应的机制来终止这些goroutine，它们会一直占用内存。
4. **缓存**：不合理地使用缓存，如缓存了大量数据但没有有效的清理策略，可能导致内存泄漏。
5. **事件监听器**：注册了事件监听器但没有及时注销，可能导致相关对象无法被回收。

### 垃圾回收（Garbage Collection）

**垃圾回收**是一种自动内存管理机制，它会自动检测并回收不再使用的内存，从而避免内存泄漏。Go语言内置了垃圾回收器，它能够自动管理内存分配和释放，减轻了程序员手动管理内存的负担。

Go语言的垃圾回收器具有以下特点：

1. **并发执行**：Go的垃圾回收器可以与程序的正常执行并发进行，减少了垃圾回收对程序性能的影响。
2. **三色标记法**：Go的垃圾回收器使用三色标记法来跟踪对象的引用状态，以此来确定哪些对象是可达的，哪些是不可达的。
3. **写屏障**：为了在并发标记过程中保证标记的正确性，Go的垃圾回收器使用了写屏障技术。
4. **自动调整**：Go的垃圾回收器能够根据程序的运行情况自动调整垃圾回收的频率和效率。
5. **低延迟**：Go的垃圾回收器设计注重减少STW（Stop The World）暂停时间，以降低对程序响应性的影响。

尽管Go语言的垃圾回收器非常高效，但程序员仍然需要注意避免内存泄漏，例如合理使用全局变量、闭包、goroutine和缓存等。

### 监控和调试

为了检测和解决内存泄漏问题，可以使用Go语言提供的一些工具：

• **pprof**：Go语言内置的性能分析工具，可以用来分析内存使用情况，帮助定位内存泄漏。
• **runtime.ReadMemStats**：通过调用`runtime`包中的`ReadMemStats`函数，可以获取程序的内存统计信息。
• **第三方工具**：如`goleak`等，可以帮助检测goroutine泄漏。

通过合理使用这些工具和方法，可以有效地监控和调试Go程序中的内存使用情况，避免内存泄漏的发生。

## 锁

#### 定义

锁是一种用于控制多个线程对共享资源进行访问的机制。在多线程或多进程环境中，多个执行单元可能同时尝试访问和修改共享资源（如内存中的数据、文件等），为了避免数据不一致或其他并发问题，引入了锁的概念，通过对共享资源加锁，同一时间只允许一个线程或进程对其进行访问。

#### 锁的分类

- 互斥锁（Mutex）
  - **原理**：也称为排他锁，同一时刻只允许一个线程持有该锁。当一个线程获取到互斥锁后，其他线程若尝试获取该锁，就会被阻塞，直到持有锁的线程释放锁。
  - **应用场景**：适用于对共享资源进行独占访问的场景，如对全局变量的读写操作。
- 读写锁（Read-Write Lock）
  - **原理**：允许多个线程同时对共享资源进行读操作，但在有线程进行写操作时，其他线程的读写操作都会被阻塞。也就是说，读操作可以并发执行，而写操作是互斥的。
  - **应用场景**：适用于读多写少的场景，如缓存系统，多个线程可以同时读取缓存数据，但只有少数线程会对缓存进行更新操作。

### 死锁

#### 定义

死锁是指两个或多个线程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。简单来说，就是每个线程都持有其他线程所需的资源，并且都在等待对方释放资源，从而导致所有线程都无法继续执行。

#### 死锁产生的四个必要条件

- **互斥条件**：进程对所分配到的资源进行排他性使用，即在一段时间内某资源只由一个进程占用。
- **请求和保持条件**：进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源已被其它进程占有，此时请求进程阻塞，但又对自己已获得的其它资源保持不放。
- **不剥夺条件**：进程已获得的资源，在未使用完之前，不能强行剥夺，只能在使用完时由自己释放。
- **环路等待条件**：在发生死锁时，必然存在一个进程——资源的环形链，即进程集合{P0，P1，P2，···，Pn}中的P0正在等待一个P1占用的资源；P1正在等待P2占用的资源，……，Pn正在等待已被P0占用的资源。

#### 死锁的避免和预防

- **死锁预防**：通过破坏死锁产生的四个必要条件之一来预防死锁的发生。例如，采用资源静态分配策略破坏请求和保持条件，或者采用可剥夺式资源分配方法破坏不剥夺条件。
- **死锁避免**：允许系统进入死锁状态的可能性，但在动态分配资源的过程中，通过某种算法来判断本次资源分配是否会导致系统进入不安全状态。如果会，则拒绝这次分配，让进程等待；如果不会，则分配资源给进程。其核心是在运行过程中动态地避免系统进入死锁状态。（如银行家算法）

#### 死锁检测和解除

- **死锁检测**：允许系统进入死锁状态，并定期运行一个算法来检测是否存在死锁。
- **死锁解除**：一旦检测到死锁，就采取措施解除死锁，常用的方法有剥夺资源和撤销进程等。

### 应用场景

- 死锁预防
  - 适用于对系统可靠性要求极高，且资源分配相对简单、固定的场景。例如，在一些实时控制系统中，为了确保系统的稳定性和正确性，会采用死锁预防的方法来避免死锁的发生。
- 死锁避免
  - 更适合于资源分配比较复杂、动态变化频繁的系统。例如，在操作系统中对进程的资源分配管理，由于进程的创建、撤销和资源需求的动态变化，采用死锁避免算法可以更好地平衡资源利用率和系统安全性 。

## 进程和线程

### 进程的概念
进程（Process）是程序在操作系统中的一次执行过程，是系统进行资源分配和调度的基本单位。每个进程都有自己独立的内存空间、代码段、数据段、堆和栈等资源，操作系统通过进程控制块（PCB，Process Control Block）来描述和管理进程，其中包含了进程的状态、优先级、程序计数器、寄存器值等重要信息。

例如，在计算机上同时打开的浏览器、文本编辑器和音乐播放器，它们在操作系统中都对应着不同的进程，各自拥有独立的运行环境和资源。

### 线程的概念
线程（Thread）是进程中的一个执行单元，是 CPU 调度和分派的基本单位。一个进程可以包含多个线程，这些线程共享该进程的资源，如内存空间、文件句柄等，但每个线程有自己独立的栈和程序计数器。

继续以浏览器进程为例，浏览器进程内部可能包含多个线程，分别负责页面渲染、网络请求、JavaScript 执行等不同的任务。

### 进程和线程的区别

#### 1. 资源分配
• **进程**：拥有独立的资源，包括内存空间、文件描述符、设备等。不同进程之间的资源相互隔离，一个进程不能直接访问另一个进程的资源，需要通过特定的进程间通信（IPC，Inter - Process Communication）机制来实现数据交换，如管道、消息队列、共享内存等。
• **线程**：同一进程内的多个线程共享该进程的大部分资源，包括代码段、数据段和堆等。线程之间可以直接访问共享的数据，这使得线程间的通信和数据共享更加方便，但也容易引发资源竞争和同步问题。

#### 2. 调度开销
• **进程**：进程切换的开销较大。当操作系统需要从一个进程切换到另一个进程时，需要保存当前进程的上下文（如寄存器值、程序计数器等），并加载新进程的上下文，这个过程涉及到大量的内存操作和系统调用，会消耗较多的时间和资源。
• **线程**：线程切换的开销相对较小。因为同一进程内的线程共享大部分资源，所以在进行线程切换时，只需要保存和恢复线程的部分上下文信息（如栈指针、程序计数器等），不需要像进程切换那样进行大规模的资源保存和加载。

#### 3. 并发性
• **进程**：不同进程可以在不同的 CPU 核心上并行执行，从而充分利用多核处理器的性能。由于进程之间相互独立，它们可以在各自的内存空间中独立运行，互不干扰。
• **线程**：同一进程内的多个线程可以在多核处理器上并行执行，也可以在单核处理器上并发执行（通过时间片轮转等调度算法）。线程的并发执行可以提高程序的执行效率，特别是在处理 I/O 密集型任务时，多个线程可以同时等待不同的 I/O 操作完成。

#### 4. 独立性
• **进程**：具有较高的独立性，一个进程的崩溃通常不会影响其他进程的正常运行。因为每个进程都有自己独立的资源和运行环境，进程之间的错误传播受到限制。
• **线程**：同一进程内的线程之间相互依赖性较强，一个线程的异常可能会导致整个进程的崩溃。因为线程共享进程的资源，当一个线程出现严重错误时，可能会破坏进程的共享数据结构，从而影响其他线程的正常执行。

## 排序

### 冒泡排序（Bubble Sort）

- **原理**：比较相邻的元素，如果顺序错误就把它们交换过来，重复此过程，直到整个数组都被排序。
- 时间复杂度
  - 最好情况：*O*(*n*)，当数组已经有序时，只需遍历一次，无需交换元素。
  - 最坏情况：*O*(n*n)，数组完全逆序时，需要进行大量的交换操作。
  - 平均情况：*O*(n*n)
- **空间复杂度**：*O*(1)，只需要常数级的额外空间用于交换元素。
- **稳定性**：稳定排序，在比较相邻元素时，如果相等则不交换位置，保证了相同元素的相对顺序不变。
- **典型应用场景**：数据量较小且对稳定性有要求的场景，或者作为教学示例来讲解排序算法的基本概念。

### 选择排序（Selection Sort）

- **原理**：在未排序序列中找到最小（大）元素，存放到排序序列的起始位置，然后，再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾，以此类推，直到所有元素均排序完毕。
- 时间复杂度
  - 最好、最坏和平均情况均为 *O*(*n*2)，因为无论数组初始状态如何，都需要进行 *n*−1 轮选择操作，每轮需要遍历未排序部分找到最小（大）元素。
- **空间复杂度**：*O*(1)，只需要常数级的额外空间。
- **稳定性**：不稳定排序，在选择最小（大）元素并与当前位置元素交换时，可能会改变相同元素的相对顺序。
- **典型应用场景**：数据量较小且对空间复杂度要求较高的场景。

### 插入排序（Insertion Sort）

- **原理**：将未排序数据插入到已排序序列的合适位置，就像打扑克牌时整理手中的牌一样。
- 时间复杂度
  - 最好情况：*O*(*n*)，当数组已经有序时，每次插入操作只需比较一次即可确定位置。
  - 最坏情况：*O*(n*n)，数组完全逆序时，每次插入都需要移动大量元素。
  - 平均情况：*O*(n*n)
- **空间复杂度**：*O*(1)，只需要常数级的额外空间用于临时存储待插入元素。
- **稳定性**：稳定排序，在插入过程中，如果遇到相等元素，会将待插入元素放在相等元素的后面，保持相对顺序不变。
- **典型应用场景**：数据量较小或者数据基本有序的场景，如在一个已经部分排序的数组上进行插入操作。

### 希尔排序（Shell Sort）

- **原理**：它是插入排序的一种改进版本，先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，待整个序列中的记录“基本有序”时，再对全体记录进行一次直接插入排序。
- 时间复杂度
  - 最好情况：*O*(*n**l**o**g**n*)，取决于增量序列的选择。
  - 最坏情况：*O*(n*n)
  - 平均情况：介于 *O*(*n*1.3) 到 *O*(*n*2) 之间，不同的增量序列会导致不同的平均时间复杂度。
- **空间复杂度**：*O*(1)，只需要常数级的额外空间。
- **稳定性**：不稳定排序，由于元素在不同子序列间移动，可能会改变相同元素的相对顺序。
- **典型应用场景**：中等规模数据的排序，在性能要求不是特别高，但又希望比简单排序算法更高效的情况下使用。

### 归并排序（Merge Sort）

- **原理**：采用分治法，将一个数组分成两个子数组，分别对这两个子数组进行排序，然后将排好序的子数组合并成一个最终的有序数组。
- 时间复杂度
  - 最好、最坏和平均情况均为 *O*(*n**l**o**g**n*)，因为每次将数组分成两部分需要 *l**o**g**n* 层递归，每层合并操作需要 *O*(*n*) 的时间。
- **空间复杂度**：*O*(*n*)，需要额外的辅助数组来存储合并过程中的临时结果。
- **稳定性**：稳定排序，在合并两个子数组时，如果遇到相等元素，会优先选择左边子数组的元素，从而保持相对顺序不变。
- **典型应用场景**：对大规模数据进行稳定排序，如外部排序（数据量太大无法全部加载到内存中），以及需要保证排序稳定性的场景。

### 快速排序（Quick Sort）

- **原理**：选择一个基准值，将数组分为两部分，使得左边部分的元素都小于等于基准值，右边部分的元素都大于等于基准值，然后分别对左右两部分递归地进行快速排序。
- 时间复杂度
  - 最好情况：*O*(*n**l**o**g**n*)，每次划分都能将数组均匀地分成两部分。
  - 最坏情况：*O*(*n*2)，当数组已经有序或接近有序时，每次划分只能得到一个比上一次划分少一个元素的子序列和一个空序列。
  - 平均情况：*O*(*n**l**o**g**n*)
- 空间复杂度
  - 最好情况：*O*(*l**o**g**n*)，递归调用栈的深度为 *l**o**g**n*。
  - 最坏情况：*O*(*n*)，递归调用栈的深度为 *n*。
- **稳定性**：不稳定排序，在划分过程中，相等元素的相对位置可能会改变。
- **典型应用场景**：大规模数据的排序，在大多数情况下性能表现优秀，广泛应用于各种编程语言的标准库中。

### 堆排序（Heap Sort）

- **原理**：利用堆这种数据结构，先将数组构建成一个最大堆（或最小堆），然后将堆顶元素与最后一个元素交换，再对剩余的元素重新调整为堆，重复此过程直到整个数组有序。
- 时间复杂度
  - 最好、最坏和平均情况均为 *O*(*n**l**o**g**n*)，构建堆的时间复杂度为 *O*(*n*)，每次调整堆的时间复杂度为 *O*(*l**o**g**n*)，共需要进行 *n*−1 次调整。
- **空间复杂度**：*O*(1)，只需要常数级的额外空间。
- **稳定性**：不稳定排序，在调整堆的过程中，可能会改变相同元素的相对顺序。
- **典型应用场景**：对大规模数据进行排序，尤其是当空间有限且不要求稳定排序时，堆排序是一个不错的选择 。

| 排序算法 | 时间复杂度（最好） | 时间复杂度（最坏） | 时间复杂度（平均）                 | 空间复杂度                   | 稳定性 | 典型应用场景                               |
| -------- | ------------------ | ------------------ | ---------------------------------- | ---------------------------- | ------ | ------------------------------------------ |
| 冒泡排序 | $O(n)$             | $O(n^2)$           | $O(n^2)$                           | $O(1)$                       | 稳定   | 数据量较小且对稳定性有要求，或作为教学示例 |
| 选择排序 | $O(n^2)$           | $O(n^2)$           | $O(n^2)$                           | $O(1)$                       | 不稳定 | 数据量较小且对空间复杂度要求较高           |
| 插入排序 | $O(n)$             | $O(n^2)$           | $O(n^2)$                           | $O(1)$                       | 稳定   | 数据量较小或者数据基本有序                 |
| 希尔排序 | -                  | $O(n^2)$           | 介于 $O(n^{1.3})$ 到 $O(n^2)$ 之间 | $O(1)$                       | 不稳定 | 中等规模数据排序                           |
| 归并排序 | $O(n log n)$       | $O(n log n)$       | $O(n log n)$                       | $O(n)$                       | 稳定   | 大规模数据稳定排序、外部排序               |
| 快速排序 | $O(n log n)$       | $O(n^2)$           | $O(n log n)$                       | 最好 $O(log n)$，最坏 $O(n)$ | 不稳定 | 大规模数据排序                             |
| 堆排序   | $O(n log n)$       | $O(n log n)$       | $O(n log n)$                       | $O(1)$                       | 不稳定 | 大规模数据排序，空间有限且不要求稳定排序   |

## 动态扩容循环队列

```go
package main

import (
	"errors"
	"fmt"
)

// CircularQueue 定义循环队列的结构
type CircularQueue struct {
	data     []interface{}
	front    int // 指向队头元素
	rear     int // 指向下一个入队的位置
	size     int // 当前队列中的元素数量
	capacity int // 队列的当前容量
}

// NewCircularQueue 初始化一个循环队列
func NewCircularQueue(initialCapacity int) *CircularQueue {
	return &CircularQueue{
		data:     make([]interface{}, initialCapacity),
		front:    0,
		rear:     0,
		size:     0,
		capacity: initialCapacity,
	}
}

// Enqueue 入队操作
func (cq *CircularQueue) Enqueue(item interface{}) error {
	if cq.size == cq.capacity {
		// 需要扩容
		newCapacity := cq.capacity * 2
		newData := make([]interface{}, newCapacity)
		if cq.front <= cq.rear {
			copy(newData, cq.data[cq.front:cq.rear])
		} else {
			n := copy(newData, cq.data[cq.front:])
			copy(newData[n:], cq.data[:cq.rear])
		}
		cq.data = newData
		cq.front = 0
		cq.rear = cq.size
		cq.capacity = newCapacity
	}

	cq.data[cq.rear] = item
	cq.rear = (cq.rear + 1) % cq.capacity
	cq.size++

	return nil
}

// Dequeue 出队操作
func (cq *CircularQueue) Dequeue() (interface{}, error) {
	if cq.size == 0 {
		return nil, errors.New("队列为空")
	}

	item := cq.data[cq.front]
	cq.data[cq.front] = nil // 清除引用，帮助垃圾回收
	cq.front = (cq.front + 1) % cq.capacity
	cq.size--

	return item, nil
}

// IsEmpty 检查队列是否为空
func (cq *CircularQueue) IsEmpty() bool {
	return cq.size == 0
}

// Size 返回队列的当前大小
func (cq *CircularQueue) Size() int {
	return cq.size
}

// 示例使用
func main() {
	cq := NewCircularQueue(3)

	// 入队
	cq.Enqueue(1)
	cq.Enqueue(2)
	cq.Enqueue(3)
	fmt.Println("队列大小:", cq.Size()) // 输出: 队列大小: 3

	// 动态扩容
	cq.Enqueue(4)
	fmt.Println("队列大小:", cq.Size()) // 输出: 队列大小: 4

	// 出队
	item, err := cq.Dequeue()
	if err != nil {
		fmt.Println("出队错误:", err)
	} else {
		fmt.Println("出队元素:", item) // 输出: 出队元素: 1
	}

	// 继续出队
	item, err = cq.Dequeue()
	if err != nil {
		fmt.Println("出队错误:", err)
	} else {
		fmt.Println("出队元素:", item) // 输出: 出队元素: 2
	}

	fmt.Println("队列大小:", cq.Size()) // 输出: 队列大小: 2
}
```

